#!/usr/bin/env python3
import os
import glob
import subprocess
import argparse
from concurrent.futures import ThreadPoolExecutor, as_completed

import pandas as pd
from tqdm import tqdm

def find_scripts(root_dir):
    """
    Return all .py files under root_dir (recursively),
    excluding this driver script itself.
    """
    pattern = os.path.join(root_dir, "**", "*.py")
    all_py = glob.glob(pattern, recursive=True)
    me = os.path.abspath(__file__)
    return sorted(f for f in all_py if os.path.abspath(f) != me)

def run_script(path):
    """
    Run `python path` and capture stdout/stderr.
    Returns dict:
      - basename: script name without .py
      - returncode
      - missing: list of missing outputs (docx, xlsx)
      - log: combined output
    """
    basename = os.path.splitext(os.path.basename(path))[0]
    proc = subprocess.run(
        ["python", path],
        stdout=subprocess.PIPE,
        stderr=subprocess.STDOUT,
        text=True,
    )
    missing = []
    for ext in ("docx", "xlsx"):
        if not os.path.exists(f"{basename}.{ext}"):
            missing.append(f"{basename}.{ext}")
    return {
        "script": path,
        "basename": basename,
        "returncode": proc.returncode,
        "missing": missing,
        "log": proc.stdout
    }

def main():
    parser = argparse.ArgumentParser(
        description="Run all Python extractors in parallel, then merge their Excel outputs."
    )
    parser.add_argument(
        "-s", "--scripts-dir", default=".",
        help="Directory under which to find all .py extractor scripts"
    )
    parser.add_argument(
        "-c", "--combined", required=True,
        help="Filename for the master Excel workbook"
    )
    parser.add_argument(
        "-j", "--max-parallel", type=int, default=3,
        help="How many scripts to run at once"
    )
    args = parser.parse_args()

    # discover all .py scripts
    scripts = find_scripts(args.scripts_dir)
    print(f"Found {len(scripts)} Python scripts under {args.scripts_dir!r}.\n")

    results = []
    # run them in parallel
    with ThreadPoolExecutor(max_workers=args.max_parallel) as exe:
        futures = { exe.submit(run_script, s): s for s in scripts }
        for fut in tqdm(as_completed(futures), total=len(futures), desc="Running scripts"):
            res = fut.result()
            results.append(res)
            if res["returncode"] != 0:
                print(f"\n[ERROR] {res['script']} failed (exit {res['returncode']}):")
                print(res["log"])
            elif res["missing"]:
                print(f"[WARN] {res['script']} missing outputs: {res['missing']}")

    total = len(results)
    success = sum(1 for r in results if r["returncode"] == 0 and not r["missing"])
    print(f"\n→ Scripts run: {total}, succeeded: {success}, failed/skipped: {total - success}\n")

    # collect all generated .xlsx in cwd
    excels = []
    for r in results:
        if r["returncode"] == 0 and ".xlsx" not in r["missing"]:
            excels.append(f"{r['basename']}.xlsx")

    if not excels:
        print("No Excel outputs found to merge. Exiting.")
        return

    # merge into one workbook
    print(f"Merging {len(excels)} Excel files into {args.combined} …")
    with pd.ExcelWriter(args.combined, engine="xlsxwriter") as writer:
        for f in tqdm(excels, desc="Merging sheets"):
            df = pd.read_excel(f)
            sheet = os.path.splitext(os.path.basename(f))[0][:31]  # Excel sheet name limit
            df.to_excel(writer, sheet_name=sheet, index=False)

    print(f"\n✅ Master workbook created: {args.combined}")
    print("Individual .docx and .xlsx files remain in the current directory.")
    
if __name__ == "__main__":
    main()
