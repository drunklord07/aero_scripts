#!/usr/bin/env python3
import os
import glob
import re
import subprocess
import argparse
import shutil
import sys
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm
import pandas as pd

# -- ASCII‐safe print to avoid Unicode errors --
def safe_print(*args, **kwargs):
    msg = " ".join(str(a) for a in args)
    msg = msg.encode("ascii", "ignore").decode("ascii")
    print(msg, **kwargs)

# Force utf-8 in child scripts
ENV = os.environ.copy()
ENV["PYTHONIOENCODING"] = "utf-8"

# Summary‐line and hits‐extraction regexes
SUMMARY_LINE_RE = re.compile(
    r"^Scanned\s+\d+\s+records,.*?hits.*$",
    re.IGNORECASE | re.MULTILINE
)
HITS_EXTRACT_RE = re.compile(r",\s*(\d+)\s+.*?hits", re.IGNORECASE)

def find_scripts():
    me = os.path.abspath(__file__)
    return sorted(
        fn for fn in glob.glob("**/*.py", recursive=True)
        if os.path.abspath(fn) != me
    )

def parse_expected_xlsx(path):
    base = os.path.splitext(os.path.basename(path))[0]
    text = open(path, encoding="utf-8", errors="ignore").read()
    m = re.search(r'OUTPUT_XLSX\s*=\s*["\'](.+?\.xlsx)["\']', text)
    return m.group(1) if m else f"{base}.xlsx"

def run_script(path):
    # Always run in base dir so input.txt is found
    exp_xlsx = parse_expected_xlsx(path)
    proc = subprocess.run(
        [sys.executable, path],
        stdout=subprocess.PIPE, stderr=subprocess.STDOUT,
        text=True, env=ENV, errors="replace"
    )
    log = proc.stdout

    # Extract summary line
    mline = SUMMARY_LINE_RE.search(log)
    summary = mline.group(0) if mline else "[no summary found]"

    # Extract hits count
    mh = HITS_EXTRACT_RE.search(summary)
    hits = int(mh.group(1)) if mh else 0

    missing = not os.path.isfile(exp_xlsx)
    return {
        "basename": os.path.splitext(os.path.basename(path))[0],
        "returncode": proc.returncode,
        "xlsx": exp_xlsx,
        "missing": missing,
        "hits": hits,
        "summary": summary,
        "log": log
    }

def main():
    base_dir = os.path.dirname(os.path.abspath(__file__))
    os.chdir(base_dir)

    parser = argparse.ArgumentParser(description="Run extractors & merge Excel outputs")
    parser.add_argument("-c","--combined", default="combined_output.xlsx")
    parser.add_argument("-j","--max-parallel", type=int, default=3)
    args = parser.parse_args()

    scripts = find_scripts()
    safe_print(f"Found {len(scripts)} scripts to run.\n")

    outputs = os.path.join(base_dir, "outputs")
    if os.path.isdir(outputs):
        shutil.rmtree(outputs)
    os.makedirs(outputs)

    total_hits = 0
    results = []
    with ThreadPoolExecutor(max_workers=args.max_parallel) as exe:
        futures = {exe.submit(run_script, s): s for s in scripts}
        for fut in tqdm(as_completed(futures),
                        total=len(futures),
                        desc="Running scripts",
                        ascii=True):
            res = fut.result()
            results.append(res)
            total_hits += res["hits"]
            name = res["basename"]

            # print status tag
            if res["returncode"] != 0:
                safe_print(f"[ERROR] {name} exited {res['returncode']}")
            elif res["missing"]:
                safe_print(f"[WARN]  {name} missing {res['xlsx']}")
            else:
                safe_print(f"[OK]    {name}")

            # print its own summary line
            safe_print("  " + res["summary"])

            # copy outputs (xlsx + docx) into outputs/
            if not res["missing"] and res["returncode"] == 0:
                src_x = res["xlsx"]
                dst_x = os.path.join(outputs, os.path.basename(src_x))
                if os.path.isfile(src_x):
                    shutil.copy(src_x, dst_x)
                src_d = os.path.splitext(src_x)[0] + ".docx"
                if os.path.isfile(src_d):
                    shutil.copy(src_d, os.path.join(outputs, os.path.basename(src_d)))

    total = len(results)
    ok = sum(1 for r in results if r["returncode"]==0 and not r["missing"])
    safe_print(f"\nScripts run: {total}, succeeded: {ok}, failed/skipped: {total-ok}")
    safe_print(f"Grand total hits: {total_hits}\n")

    excels = sorted(f for f in os.listdir(outputs) if f.endswith(".xlsx"))
    if not excels:
        safe_print("No Excel files to merge. Exiting.")
        sys.exit(1)

    safe_print(f"Merging {len(excels)} Excel files into '{args.combined}' …")
    with pd.ExcelWriter(args.combined, engine="xlsxwriter") as writer:
        for fname in tqdm(excels, desc="Merging", ascii=True):
            path = os.path.join(outputs, fname)
            try:
                df = pd.read_excel(path)
            except Exception as e:
                safe_print(f"[WARN] could not read {fname}: {e}")
                continue
            sheet = os.path.splitext(fname)[0][:31]
            df.to_excel(writer, sheet_name=sheet, index=False)

    safe_print(f"\nMaster workbook created: {os.path.abspath(args.combined)}")
    safe_print(f"All outputs in: {os.path.abspath(outputs)}")
    sys.exit(0 if ok==total else 1)

if __name__ == "__main__":
    main()
