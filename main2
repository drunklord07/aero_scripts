#!/usr/bin/env python3
import os
import glob
import re
import subprocess
import argparse
import shutil
import sys
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm
import pandas as pd

# -- ASCII‐safe print to avoid Unicode errors --
def safe_print(*args, **kwargs):
    msg = " ".join(str(a) for a in args)
    msg = msg.encode("ascii", "ignore").decode("ascii")
    print(msg, **kwargs)

# Force utf-8 in child scripts
ENV = os.environ.copy()
ENV["PYTHONIOENCODING"] = "utf-8"

# Extractor summary regex
SUMMARY_LINE_RE = re.compile(r"Scanned\s+\d+\s+records,.*?hits", re.IGNORECASE)
HITS_EXTRACT_RE = re.compile(r",\s*(\d+)\s+.*?hits", re.IGNORECASE)

def find_scripts():
    me = os.path.abspath(__file__)
    return sorted(
        fn for fn in glob.glob("**/*.py", recursive=True)
        if os.path.abspath(fn) != me
    )

def parse_expected_xlsx(path):
    base = os.path.splitext(os.path.basename(path))[0]
    txt  = open(path, encoding="utf-8", errors="ignore").read()
    m    = re.search(r'OUTPUT_XLSX\s*=\s*["\'](.+?\.xlsx)["\']', txt)
    return m.group(1) if m else f"{base}.xlsx"

def run_script(path):
    xlsx = parse_expected_xlsx(path)
    proc = subprocess.run(
        [sys.executable, path],
        stdout=subprocess.PIPE, stderr=subprocess.STDOUT,
        text=True, env=ENV, errors="replace"
    )
    log = proc.stdout

    # find summary line
    summary = "[no summary found]"
    for ln in log.splitlines():
        if "records" in ln.lower() and "hits" in ln.lower():
            summary = ln.strip()
            break

    # extract hits
    mh = HITS_EXTRACT_RE.search(summary)
    hits = int(mh.group(1)) if mh else 0

    missing = not os.path.isfile(xlsx)
    return {
        "basename": os.path.splitext(os.path.basename(path))[0],
        "returncode": proc.returncode,
        "xlsx": xlsx,
        "missing": missing,
        "hits": hits,
        "summary": summary,
        "log": log
    }

def main():
    base_dir = os.path.dirname(os.path.abspath(__file__))
    os.chdir(base_dir)

    parser = argparse.ArgumentParser()
    parser.add_argument("-c","--combined",default="combined_output.xlsx")
    parser.add_argument("-j","--max-parallel",type=int,default=3)
    args = parser.parse_args()

    scripts = find_scripts()
    safe_print(f"Found {len(scripts)} scripts to run.\n")

    outputs = os.path.join(base_dir, "outputs")
    if os.path.isdir(outputs):
        shutil.rmtree(outputs)
    os.makedirs(outputs)

    total_hits = 0
    results = []
    for fut in tqdm(ThreadPoolExecutor(max_workers=args.max_parallel)
                    .map(lambda s: run_script(s), scripts),
                    total=len(scripts),
                    desc="Running scripts",
                    ascii=True):
        res = fut
        results.append(res)
        total_hits += res["hits"]
        name = res["basename"]

        # status
        if res["returncode"] != 0:
            safe_print(f"[ERROR] {name} exited {res['returncode']}")
        elif res["missing"]:
            safe_print(f"[WARN]  {name} missing {res['xlsx']}")
        else:
            safe_print(f"[OK]    {name}")

        # summary
        safe_print(f"  {res['summary']}")

        # JSON parse failures block
        in_fail = False
        for ln in res["log"].splitlines():
            if "json parse failure" in ln.lower():
                in_fail = True
                safe_print(f"  {ln.strip()}")
            elif in_fail and ln.startswith("  "):
                safe_print(f"  {ln.strip()}")
            elif in_fail:
                break

        # copy artifacts
        if res["returncode"] == 0 and not res["missing"]:
            for fn in (res["xlsx"], res["xlsx"][:-5] + ".docx"):
                if os.path.isfile(fn):
                    shutil.copy(fn, outputs)

    total = len(results)
    ok = sum(1 for r in results if r["returncode"]==0 and not r["missing"])
    safe_print(f"\nScripts run: {total}, succeeded: {ok}, failed/skipped: {total-ok}")
    safe_print(f"Grand total hits: {total_hits}\n")

    excels = sorted(f for f in os.listdir(outputs) if f.endswith(".xlsx"))
    if not excels:
        safe_print("No Excel files to merge. Exiting.")
        sys.exit(1)

    safe_print(f"Merging {len(excels)} Excel files into '{args.combined}' …")
    with pd.ExcelWriter(args.combined, engine="xlsxwriter") as writer:
        for fname in tqdm(excels, desc="Merging", ascii=True):
            path = os.path.join(outputs, fname)
            sheet = os.path.splitext(fname)[0][:31]
            try:
                df = pd.read_excel(path, dtype=str)
                df.to_excel(writer, sheet_name=sheet, index=False)
            except Exception as e:
                safe_print(f"[WARN] could not read {fname}: {e}")
                writer.book.add_worksheet(sheet)

    safe_print(f"\nMaster workbook: {os.path.abspath(args.combined)}")
    safe_print(f"All outputs in: {os.path.abspath(outputs)}")
    sys.exit(0 if ok==total else 1)

if __name__=="__main__":
    main()
