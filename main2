#!/usr/bin/env python3
import os
import glob
import re
import subprocess
import argparse
import shutil
import sys
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm
import pandas as pd

# ASCII-safe print
def safe_print(*args, **kwargs):
    msg = " ".join(str(a) for a in args)
    msg = msg.encode("ascii", "ignore").decode("ascii")
    print(msg, **kwargs)

# Ensure child scripts print UTF-8 safely
ENV = os.environ.copy()
ENV["PYTHONIOENCODING"] = "utf-8"

# For grabbing summary & hits
SUMMARY_RE = re.compile(r"records.*?hits", re.IGNORECASE)
HITS_RE    = re.compile(r",\s*(\d+)\s+.*?hits", re.IGNORECASE)
PARSE_FAIL_RE = re.compile(r"JSON parse failures?:", re.IGNORECASE)

def find_scripts():
    me = os.path.abspath(__file__)
    return sorted(fn for fn in glob.glob("**/*.py", recursive=True) if os.path.abspath(fn) != me)

def parse_expected_xlsx(path):
    base = os.path.splitext(os.path.basename(path))[0]
    txt  = open(path, encoding="utf-8", errors="ignore").read()
    m    = re.search(r'OUTPUT_XLSX\s*=\s*["\'](.+?\.xlsx)["\']', txt)
    return m.group(1) if m else f"{base}.xlsx"

def run_script(path):
    xlsx = parse_expected_xlsx(path)
    # Run in project root so input.txt is found
    proc = subprocess.run(
        [sys.executable, path],
        stdout=subprocess.PIPE, stderr=subprocess.STDOUT,
        text=True, env=ENV, errors="replace"
    )
    log = proc.stdout
    # find summary line
    summary = "[no summary found]"
    for ln in log.splitlines():
        if SUMMARY_RE.search(ln):
            summary = ln.strip()
            break
    # extract hits
    mh = HITS_RE.search(summary)
    hits = int(mh.group(1)) if mh else 0
    # collect parse failure lines
    pf_lines = []
    in_pf = False
    for ln in log.splitlines():
        if PARSE_FAIL_RE.search(ln):
            in_pf = True
            pf_lines.append(ln.strip())
        elif in_pf:
            if ln.strip().startswith("-") or ln.strip():
                pf_lines.append(ln.strip())
            else:
                break
    # did .xlsx appear?
    missing = not os.path.isfile(xlsx)
    return {
        "basename": os.path.splitext(os.path.basename(path))[0],
        "returncode": proc.returncode,
        "xlsx": xlsx,
        "missing": missing,
        "hits": hits,
        "summary": summary,
        "parse_failures": pf_lines,
        "log": log
    }

def main():
    base = os.path.dirname(os.path.abspath(__file__))
    os.chdir(base)

    p = argparse.ArgumentParser()
    p.add_argument("-c","--combined",default="combined_output.xlsx")
    p.add_argument("-j","--max-parallel",type=int,default=3)
    args = p.parse_args()

    scripts = find_scripts()
    safe_print(f"Found {len(scripts)} scripts.\n")

    out_dir = os.path.join(base, "outputs")
    if os.path.isdir(out_dir):
        shutil.rmtree(out_dir)
    os.makedirs(out_dir)

    results = []
    total_hits = 0

    with ThreadPoolExecutor(max_workers=args.max_parallel) as exe:
        futures = {exe.submit(run_script, s): s for s in scripts}
        for fut in tqdm(as_completed(futures),
                        total=len(futures),
                        desc="Running scripts",
                        ascii=True):
            res = fut.result()
            results.append(res)
            total_hits += res["hits"]
            name = res["basename"]

            # Status
            if res["returncode"] != 0:
                safe_print(f"[ERROR] {name} exited {res['returncode']}")
            elif res["missing"]:
                safe_print(f"[WARN]  {name} missing {res['xlsx']}")
            else:
                safe_print(f"[OK]    {name}")

            # Summary
            safe_print("  " + res["summary"])

            # JSON parse failures
            for pf in res["parse_failures"]:
                safe_print("   " + pf)

            # Move outputs
            if res["returncode"] == 0 and not res["missing"]:
                # move xlsx
                if os.path.isfile(res["xlsx"]):
                    shutil.move(res["xlsx"], os.path.join(out_dir, res["xlsx"]))
                # move docx if exists
                docx = res["xlsx"][:-5] + ".docx"
                if os.path.isfile(docx):
                    shutil.move(docx, os.path.join(out_dir, os.path.basename(docx)))

    total = len(results)
    ok = sum(1 for r in results if r["returncode"]==0 and not r["missing"])
    safe_print(f"\nScripts run: {total}, succeeded: {ok}, failed/skipped: {total-ok}")
    safe_print(f"Grand total hits: {total_hits}\n")

    excels = sorted(f for f in os.listdir(out_dir) if f.endswith(".xlsx"))
    if not excels:
        safe_print("No Excel files to merge.")
        sys.exit(1)

    safe_print(f"Merging {len(excels)} Excel files into '{args.combined}' â€¦")
    with pd.ExcelWriter(args.combined, engine="xlsxwriter") as writer:
        for fname in tqdm(excels, desc="Merging", ascii=True):
            path = os.path.join(out_dir, fname)
            sheet = os.path.splitext(fname)[0][:31]
            try:
                df = pd.read_excel(path, dtype=str)
                df.to_excel(writer, sheet_name=sheet, index=False)
            except Exception:
                writer.book.add_worksheet(sheet)

    safe_print(f"\nMaster workbook: {os.path.abspath(args.combined)}")
    safe_print(f"All outputs in: {os.path.abspath(out_dir)}")
    sys.exit(0 if ok==total else 1)

if __name__=="__main__":
    main()
